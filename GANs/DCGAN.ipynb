{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL      import Image\n",
    "from datetime import datetime\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models   import Sequential, Model\n",
    "from keras.layers   import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional        import UpSampling2D, Conv2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "np.random.RandomState(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    \n",
    "    def __init__(self, name=\"dcgan\", shape=(128,128,3), r=5, c=5):\n",
    "        \n",
    "        self.path_imgs        = \"./images/%s/\" % name\n",
    "        self.path_imgs_latent = \"./images/%s/latent/\" % name        \n",
    "        self.path_models      = \"./saved_model/%s/\"   % name\n",
    "        for d in [\"./images\", \"./saved_model/\", self.path_imgs, self.path_imgs_latent, self.path_models]: \n",
    "            if not os.path.exists(d):\n",
    "                print(\"Create a new directory, '%s'.\" % d)\n",
    "                os.mkdir(d)\n",
    "\n",
    "        self.shape = shape\n",
    "        self.z_dim = 100\n",
    "        self.hist  = []\n",
    "        \n",
    "        self.r = r\n",
    "        self.c = c\n",
    "        self.check_noise = np.random.uniform(-1, 1, (r * c, self.z_dim))\n",
    "\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss      = \"binary_crossentropy\",\n",
    "                                   optimizer = Adam(lr=0.0002, beta_1=0.5),\n",
    "                                   metrics   = [\"accuracy\"])\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        z   = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        valid = self.discriminator(img)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss      = \"binary_crossentropy\",\n",
    "                              optimizer = Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * int(self.shape[0]/4) * int(self.shape[0]/4), activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((int(self.shape[0]/4), int(self.shape[0]/4), 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(self.shape[2], kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img   = model(noise)\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        img      = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def set_weights(self, g_weights, d_weights):\n",
    "        # Load generator weights\n",
    "        if -1 < g_weights.find(\"/\"):\n",
    "            self.generator.load_weights(g_weights)\n",
    "        else:\n",
    "            self.generator.load_weights(self.path_models + g_weights)\n",
    "        # Load discriminator weights\n",
    "        if -1 < d_weights.find(\"/\"):\n",
    "            self.discriminator.load_weights(d_weights)\n",
    "        else:\n",
    "            self.discriminator.load_weights(self.path_models + d_weights)\n",
    "\n",
    "    def train(self, X, iterations, batch_size=128, save_interval=50, model_interval=100):\n",
    "        start_time = datetime.now()\n",
    "        half_batch = int(batch_size / 2)\n",
    "        X_train    = (X.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            # Training Discriminator\n",
    "            idx   = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs  = X_train[idx]\n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs,     np.ones ((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss      = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Training Generator\n",
    "            noise  = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            self.hist.append([iteration, d_loss[0], 100 * d_loss[1], g_loss])\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration)\n",
    "                sta = np.expand_dims(self.check_noise[0], axis=0)\n",
    "                end = np.expand_dims(self.check_noise[1], axis=0)\n",
    "                resultImage = self.visualize_interpolation(sta, end)\n",
    "                cv2.imwrite(self.path_imgs_latent + \"latent_%s.png\" % iteration, resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    self.generator.save    (self.path_models + \"generator_%s.h5\"     % iteration)\n",
    "                    self.discriminator.save(self.path_models + \"discriminator_%s.h5\" % iteration)\n",
    "\n",
    "    def save_imgs(self, iteration):\n",
    "        noise    = self.check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        fig, axs = plt.subplots(self.r, self.c)\n",
    "        cnt = 0\n",
    "        for i in range(self.r):\n",
    "            for j in range(self.c):\n",
    "                if gen_imgs.shape[3]==1:\n",
    "                    axs[i, j].imshow(gen_imgs[cnt, :, :, 0])  # gray\n",
    "                else:\n",
    "                    axs[i, j].imshow(gen_imgs[cnt, :, :, :])  # color      \n",
    "                axs[i, j].axis(\"off\")\n",
    "                cnt += 1\n",
    "        fig.savefig(self.path_imgs + \"%s.png\" % iteration)\n",
    "        plt.close()\n",
    "\n",
    "    def visualize_interpolation(self, start, end, save=True, nbSteps=10):\n",
    "        steps       = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd   = end\n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg   = self.generator.predict(latentEnd)\n",
    "        vectors  = []\n",
    "        for alpha in np.linspace(0, 1, steps):\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultImage = None\n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "        return resultImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = \"cifar10\"\n",
    "dcgan = DCGAN(path, shape=(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan.train(x_train, iterations=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
