{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, math, tarfile, gzip, zipfile\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape, Flatten, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    if not os.path.exists(path): os.mkdir(path)\n",
    "        \n",
    "def load_data_gz(path, resize):\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        imgs = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,*resize)\n",
    "    f.close()\n",
    "    print(\"データ件数：%s、縦：%s、横：%s、チャンネル数：%s\" % (imgs.shape[0], imgs.shape[1], imgs.shape[2], 1))\n",
    "    return imgs.astype(int)\n",
    "\n",
    "def load_data_zip(path, resize):\n",
    "    with zipfile.ZipFile(path, 'r') as zf:\n",
    "        file_num, img_num = len(zf.namelist()), 0\n",
    "        imgs = np.empty((file_num, *resize, 3))\n",
    "        for idx, f in enumerate(zf.namelist()):\n",
    "            try:\n",
    "                img      = Image.open(io.BytesIO(zf.read(f))).resize(resize)\n",
    "                img_ary  = np.array(img)\n",
    "                imgs[img_num,:,:,:] = img_ary\n",
    "                img_num += 1\n",
    "            except:\n",
    "                print(f, \"は読み込めませんでした。\")\n",
    "        print(\"%s/%s ファイル読み込めました。\" % (img_num, file_num))\n",
    "        return imgs[:img_num]\n",
    "\n",
    "def load_data_tar(path, names, resize):\n",
    "    imgs = np.empty((len(names)*1000, *resize, 3))\n",
    "    num  = 0\n",
    "    tar  = tarfile.open(path, 'r')\n",
    "    for ti in tar:\n",
    "        if sum([1 if -1 < ti.name.find(n) else 0 for n in names]) == 0:\n",
    "            continue\n",
    "        if ti.name.find(\".jpg\")==-1:\n",
    "            print(\"%sを読み込んでいます。\" % ti.name)\n",
    "            continue\n",
    "        try:\n",
    "            img = tar.extractfile(ti.name)\n",
    "            img = Image.open(io.BytesIO(img.read())).resize(resize)\n",
    "            imgs[num,:,:,:] = np.array(img)\n",
    "            num += 1\n",
    "        except:\n",
    "            print(\"%sは読み込めませんでした。\" % ti.name)\n",
    "    tar.close()\n",
    "    imgs = imgs[:num]\n",
    "    print(\"データ件数：%s、縦：%s、横：%s、チャンネル数：%s\" % (imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]))\n",
    "    return imgs.astype(int)\n",
    "\n",
    "def combine_images(generated_images, generated_images_path,\n",
    "                   epoch=\"\", index=\"\", save=True, show=True):\n",
    "    total = generated_images.shape[0]\n",
    "    cols  = int(math.sqrt(total))\n",
    "    rows  = math.ceil(float(total)/cols)\n",
    "    plt.figure(figsize=(4, 4), dpi=170)\n",
    "    if epoch != \"\" and index != \"\":\n",
    "        plt.suptitle('epoch=%04d,index=%04d' % (epoch, index), fontsize=10)\n",
    "    for i in range(total):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(generated_images[i].astype(int))\n",
    "        plt.gray()\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "    if save:\n",
    "        filename = generated_images_path + \"%04d_%04d.png\" % (epoch, index)\n",
    "        plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dcgan():\n",
    "    \n",
    "    def __init__(self, path, inputs_shape):\n",
    "        self.path_imgs    = path + \"generated_images/\"\n",
    "        self.path_models  = path + \"models/\"\n",
    "        mkdir(path)\n",
    "        mkdir(self.path_imgs)\n",
    "        mkdir(self.path_models)\n",
    "        self.inputs_shape = inputs_shape\n",
    "        self.units        = int(inputs_shape[0]/4)\n",
    "        self.history      = []\n",
    "    \n",
    "    def generator_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(input_dim=100, units=1024))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(self.units*self.units*128))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Reshape((self.units, self.units, 128), input_shape=(self.units*self.units*128,)))\n",
    "        model.add(UpSampling2D(size=(2, 2)))\n",
    "        model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(UpSampling2D(size=(2, 2)))\n",
    "        model.add(Conv2D(self.inputs_shape[2], (5, 5), padding='same'))\n",
    "        model.add(Activation('tanh'))\n",
    "        return model\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=self.inputs_shape))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(Conv2D(128, (5, 5), strides=(2, 2)))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(Conv2D(256, (5, 5), strides=(2, 2)))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        return model\n",
    "    \n",
    "    def create_models(self):\n",
    "        self.D = self.discriminator_model()\n",
    "        self.G = self.generator_model()\n",
    "        self.D.trainable = False\n",
    "        self.DCGAN       = Sequential([self.G, self.D])\n",
    "        self.DCGAN.compile(loss='binary_crossentropy',\n",
    "                           optimizer=Adam(lr=2e-4, beta_1=0.5))\n",
    "        self.D.trainable = True\n",
    "        self.D.compile(loss='binary_crossentropy',\n",
    "                       optimizer=Adam(lr=1e-5, beta_1=0.1))\n",
    "        self.G.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        \n",
    "    def set_weights(self, g_weights, d_weights):\n",
    "        self.G.load_weights(self.path_models + g_weights)\n",
    "        self.D.load_weights(self.path_models + d_weights)\n",
    "        \n",
    "    def generate_images(self, save=False, show=True):\n",
    "        noise = np.random.uniform(-1, 1, size=(self.batch_size, 100))\n",
    "        generated_images = self.G.predict(noise, verbose=0)\n",
    "        plot_data = generated_images.astype('float32')*127.5 + 127.5\n",
    "        if self.inputs_shape[2]==1:\n",
    "            plot_data = plot_data.reshape((self.batch_size, *self.inputs_shape[:2]))\n",
    "        else:\n",
    "            plot_data = plot_data.reshape((self.batch_size, *self.inputs_shape))\n",
    "        combine_images(plot_data, self.path_imgs, 9999, 9999, save=save, show=show)\n",
    "        \n",
    "    def fit(self, x, batch, start, end, batch_output=0, epoch_output=0):\n",
    "        start_time = datetime.now()\n",
    "        self.batch_size = batch\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        # 学習データの値域を -1 ～ 1 にする\n",
    "        x_train = (x.astype(np.float32) - 127.5)/127.5\n",
    "        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], self.inputs_shape[2])\n",
    "        # 学習開始\n",
    "        num_batches = int(x_train.shape[0] / batch)\n",
    "        print('Number of batches:', num_batches)\n",
    "        for epoch in range(start, end):\n",
    "            for index in range(num_batches):\n",
    "                noise       = np.random.uniform(-1, 1, size=(batch, 100))\n",
    "                image_batch = x_train[index*batch : (index+1)*batch]\n",
    "                generated_images = self.G.predict(noise, verbose=0)\n",
    "                if (batch_output!=0 and index % batch_output==0) or \\\n",
    "                    (epoch_output!=0 and index==0 and (epoch+1) % epoch_output==0) or \\\n",
    "                    (epoch_output!=0 and index==0 and epoch==0):\n",
    "                    # 生成画像を出力\n",
    "                    plot_data = generated_images.astype('float32')*127.5 + 127.5\n",
    "                    if self.inputs_shape[2]==1:\n",
    "                        plot_data = plot_data.reshape((batch, *self.inputs_shape[:2]))\n",
    "                    else:\n",
    "                        plot_data = plot_data.reshape((batch, *self.inputs_shape))\n",
    "                    combine_images(plot_data, self.path_imgs, epoch, index)\n",
    "                    # モデルの保存\n",
    "                    time = datetime.strftime(datetime.now(), \"%Y%m%d%H%M%S\")\n",
    "                    self.G.save_weights(\"%sgenerator_%s.h5\" % (self.path_models, time))\n",
    "                    self.D.save_weights(\"%sdiscriminator_%s.h5\" % (self.path_models, time))\n",
    "                    # 履歴の保存\n",
    "                    self.history = [g_losses, d_losses]\n",
    "                    print(\"epoch: %d, batch: %d, time: %s\" % (epoch, index, datetime.now()-start_time))\n",
    "                # discriminatorを更新\n",
    "                d_x = np.concatenate((image_batch, generated_images))\n",
    "                y   = [1]*batch + [0]*batch\n",
    "                d_loss = self.D.train_on_batch(d_x, y)\n",
    "                # generatorを更新\n",
    "                noise  = np.random.uniform(-1, 1, size=(batch, 100))\n",
    "                self.D.trainable = False\n",
    "                g_loss = self.DCGAN.train_on_batch(noise, [1]*batch)\n",
    "                self.D.trainable = True\n",
    "                # 履歴の保存\n",
    "                g_losses.append(g_loss)\n",
    "                d_losses.append(d_loss)\n",
    "        # モデルの保存\n",
    "        time = datetime.strftime(datetime.now(), \"%Y%m%d%H%M%S\")\n",
    "        self.G.save_weights(\"%sgenerator_%s_latest_model.h5\" % (self.path_models, time))\n",
    "        self.D.save_weights(\"%sdiscriminator_%s_latest_model.h5\" % (self.path_models, time))\n",
    "        print(\"finished. time: %s\" % (datetime.now()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path   = \"./data/fashion_mnist_train_data.gz\"\n",
    "resize = (28,28)\n",
    "imgs   = load_data_gz(path, resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0   # 何枚目から\n",
    "end   = 64  # 何枚目まで表示するか（64枚だと綺麗に描画される）\n",
    "combine_images(imgs[start:end], \"\", save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path  = \"./fashion_mnsit/\"\n",
    "inputs_shape = (28,28,1)\n",
    "dcgan_fashion_mnist = dcgan(models_path, inputs_shape)\n",
    "dcgan_fashion_mnist.create_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 設定値\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH  = 2\n",
    "OUTPUT_NUM = 300  # 300回学習ごとに途中結果を描画＆保存\n",
    "#############################################\n",
    "\n",
    "start_epoch = 0\n",
    "continuous  = [int(f.split(\"_\")[0]) for f in os.listdir(dcgan_fashion_mnist.path_imgs) if -1 < f.find(\"png\")]\n",
    "if continuous != []: start_epoch = max(continuous) + 1\n",
    "end_epoch   = start_epoch + NUM_EPOCH\n",
    "\n",
    "dcgan_fashion_mnist.fit(imgs, BATCH_SIZE, start_epoch, end_epoch, batch_output=OUTPUT_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## food101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path   = \"./data/　　ここにファイル名をいれる　　.zip\"\n",
    "resize = (64,64)\n",
    "imgs   = load_data_zip(path, resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0   # 何枚目から\n",
    "end   = 64  # 何枚目まで表示するか（64画像が綺麗に描画される）\n",
    "combine_images(imgs[start:end], \"\", save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path  = \"./food/\"\n",
    "inputs_shape = (64,64,3)\n",
    "dcgan_food = dcgan(models_path, inputs_shape)\n",
    "dcgan_food.create_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 設定値\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH  = 200\n",
    "OUTPUT_NUM = 10  # 10エポックごとに途中結果を描画＆保存\n",
    "#############################################\n",
    "\n",
    "start_epoch = 0\n",
    "continuous  = [int(f.split(\"_\")[0]) for f in os.listdir(dcgan_food.path_imgs) if -1 < f.find(\"png\")]\n",
    "if continuous != []: start_epoch = max(continuous) + 1\n",
    "end_epoch   = start_epoch + NUM_EPOCH\n",
    "\n",
    "dcgan_food.fit(imgs, BATCH_SIZE, start_epoch, end_epoch, epoch_output=OUTPUT_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルでの画像生成を行う場合に使用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 設定値\n",
    "D_WEIGHTS = \"\"\n",
    "G_WEIGHTS = \"\"\n",
    "#############################################\n",
    "\n",
    "models_path  = \"./fashion_mnsit/\"\n",
    "inputs_shape = (28,28,1)\n",
    "dcgan_fashion_mnist = dcgan(models_path, inputs_shape)\n",
    "dcgan_fashion_mnist.create_models()\n",
    "dcgan_fashion_mnist.set_weights(g_weights=G_WEIGHTS, d_weights=D_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan_fashion_mnist.generate_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 設定値\n",
    "D_WEIGHTS = \"\"\n",
    "G_WEIGHTS = \"\"\n",
    "#############################################\n",
    "\n",
    "models_path  = \"./food/\"\n",
    "inputs_shape = (64,64,3)\n",
    "dcgan_food = dcgan(models_path, inputs_shape)\n",
    "dcgan_food.create_models()\n",
    "dcgan_food.set_weights(g_weights=G_WEIGHTS, d_weights=D_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan_food.generate_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
